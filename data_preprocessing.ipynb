{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 73 \n",
    "N_FOLDS = 21\n",
    "RND_SEED = 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#####  set default dir ##### \n",
    "### os.chdir('./kaggle-Rain/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### 1. Import training data and extract ids #######\n",
    "train_raw = pd.read_csv(\"./data/train.csv\")\n",
    "# train_raw = pd.read_csv(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id\n",
       "1             0.254000\n",
       "2             1.016000\n",
       "3            26.162014\n",
       "4             4.064002\n",
       "5           774.700440\n",
       "6             0.254000\n",
       "7             0.508000\n",
       "8             3.225002\n",
       "9            18.288010\n",
       "10            0.010000\n",
       "11            2.540001\n",
       "12            3.302002\n",
       "13            0.254000\n",
       "14            1.270001\n",
       "15            2.286001\n",
       "16         1308.100700\n",
       "17            0.060000\n",
       "18            1.524001\n",
       "19            3.810002\n",
       "20            0.254000\n",
       "21           28.000013\n",
       "22          166.370090\n",
       "23            1.270001\n",
       "24            1.075001\n",
       "25            1.016000\n",
       "26            1.016000\n",
       "27            2.540001\n",
       "28            1.016000\n",
       "29            1.524001\n",
       "30            0.254000\n",
       "              ...     \n",
       "1180916    2009.903100\n",
       "1180917     100.000050\n",
       "1180918       0.254000\n",
       "1180919       1.778001\n",
       "1180920       0.254000\n",
       "1180921       0.508000\n",
       "1180922    2627.885300\n",
       "1180923      15.494008\n",
       "1180924       2.794001\n",
       "1180925       1.778001\n",
       "1180926       0.508000\n",
       "1180927       1.524001\n",
       "1180928       2.794001\n",
       "1180929       0.762000\n",
       "1180930       0.254000\n",
       "1180931       0.254000\n",
       "1180932       1.778001\n",
       "1180933       0.508000\n",
       "1180934       2.540001\n",
       "1180935       0.508000\n",
       "1180936      26.162014\n",
       "1180937    2945.131600\n",
       "1180938       0.508000\n",
       "1180939     166.370090\n",
       "1180940    2503.425300\n",
       "1180941    1728.978900\n",
       "1180942       1.524001\n",
       "1180943       0.254000\n",
       "1180944       3.556002\n",
       "1180945       8.636004\n",
       "Name: Expected, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.groupby('Id').Expected.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_ids_all = train_raw[\"Id\"]\n",
    "raw_ids = raw_ids_all.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### 2. Remove ids with only NaNs in the \"Ref\" column #######\n",
    "train_raw_tmp = train_raw[~np.isnan(train_raw.Ref)]\n",
    "raw_ids_tmp = train_raw_tmp[\"Id\"].unique()\n",
    "train_new = train_raw[np.in1d(raw_ids_all, raw_ids_tmp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9125329, 24)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### 3. Convert all NaN to zero #######\n",
    "train_new = train_new.fillna(0.0)\n",
    "train_new = train_new.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### 4. Define and exclude outliers from training set #######\n",
    "train_new_group = train_new.groupby('Id')\n",
    "df = pd.DataFrame(train_new_group['Expected'].mean()) # mean, or any value\n",
    "meaningful_ids = np.array(df[df['Expected'] < THRESHOLD].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### 5. Split off holdout validation subset #######\n",
    "# Count the no. of observations per hour for each gauge reading\n",
    "train_new_ids_all = train_new[\"Id\"]\n",
    "obs_freq = train_new_ids_all.value_counts(ascending=True)\n",
    "obs_bins = obs_freq.unique()\n",
    "obs_num = ([(obs_freq==i).sum() for i in obs_bins])\n",
    "obs_ids = [np.array(obs_freq.index[obs_freq.values==i]) for i in obs_bins]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct stratified c.v. holdout set w.r.t. no. observations per hour\n",
    "y = np.array(obs_freq)\n",
    "X = np.concatenate(obs_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(RND_SEED)\n",
    "skf = cross_validation.StratifiedKFold(y, n_folds=N_FOLDS, shuffle=True,\n",
    "                                       random_state=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.cross_validation.StratifiedKFold(labels=[ 1  1  1 ..., 19 19 19], n_folds=21, shuffle=True, random_state=<mtrand.RandomState object at 0x7f52a8b81168>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_list = []\n",
    "X_valid_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape before: 696708\n",
      "train.shape after: 680780\n",
      "valid.shape: 34848\n"
     ]
    }
   ],
   "source": [
    "cv = 20\n",
    "for train_index, valid_index in skf:\n",
    "    X_train, X_valid = X[train_index], X[valid_index]\n",
    "    print(\"train.shape before: %s\" % (X_train.shape))\n",
    "    X_train = X_train[np.in1d(X_train, meaningful_ids)]\n",
    "    \n",
    "    X_train_list.append(X_train)\n",
    "    X_valid_list.append(X_valid)\n",
    "    print(\"train.shape after: %s\" % (X_train.shape))\n",
    "    print(\"valid.shape: %s\" % (X_valid.shape))\n",
    "    \n",
    "    cv += 1\n",
    "    break # remove if full n-fold cross-validation is desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"./data/processed_train\", np.array(train_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### 5. Save the partitioned IDs into folders #######\n",
    "if not os.path.exists(\"train\"):\n",
    "    os.makedirs(\"train\")\n",
    "if not os.path.exists(\"valid\"):\n",
    "    os.makedirs(\"valid\")\n",
    "if not os.path.exists(\"test\"):\n",
    "    os.makedirs(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, item in enumerate(X_train_list):\n",
    "    np.save(\"./train/obs_ids_train_cv%s\" % (i), item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, item in enumerate(X_valid_list):\n",
    "    np.save(\"./valid/obs_ids_valid_cv%s\" % (i), item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### 6. Preprocess the test data #######\n",
    "test_raw = pd.read_csv(\"./data/test.csv\")\n",
    "test_raw_ids_all = test_raw[\"Id\"]\n",
    "test_raw_ids = np.array(test_raw_ids_all.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert all NaNs to zero\n",
    "test_new = test_raw.fillna(0.0)\n",
    "test_new = test_new.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"./data/processed_test\", np.array(test_new))\n",
    "np.save(\"./test/obs_ids_test\", test_raw_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
